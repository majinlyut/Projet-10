import os
import json
import streamlit as st
from mistralai.client import MistralClient
from mistralai.models.chat_completion import ChatMessage
from dotenv import load_dotenv
from langchain_community.vectorstores import FAISS
from langchain_core.embeddings import Embeddings

# --- Mistral API key ---
load_dotenv()
api_key = os.getenv("MISTRAL_API_KEY")
model = "mistral-medium"

if not api_key:
    st.error("âŒ ClÃ© API Mistral non trouvÃ©e.")
    st.stop()

client = MistralClient(api_key=api_key)

# --- Embeddings wrapper ---
class CustomMistralEmbeddings(Embeddings):
    def __init__(self, client):
        self.client = client
    def embed_documents(self, texts):
        response = self.client.embeddings(model="mistral-embed", input=texts)
        return [res.embedding for res in response.data]
    def embed_query(self, text):
        return self.embed_documents([text])[0]

embedding_function = CustomMistralEmbeddings(client)

# --- Chargement index FAISS ---
try:
    vectorstore = FAISS.load_local(
        "faiss_langchain_index",
        embeddings=embedding_function,
        allow_dangerous_deserialization=True
    )
except Exception as e:
    st.error(f"âŒ Erreur chargement index FAISS : {e}")
    st.stop()

# --- Prompt systÃ¨me ---
SYSTEM_PROMPT = """Tu es un assistant culturel pour Paris.

Ta mission est de recommander des Ã©vÃ©nements aux utilisateurs en te basant uniquement sur le CONTEXTE fourni ci-dessous.

Quand tu cites un Ã©vÃ©nement, respecte **strictement** le format suivant (avec des sauts de ligne et le bon usage du Markdown) :

ğŸ“Œ **{{title}}**  
ğŸ“ _Lieu : {{lieu}}_  
ğŸ  _Adresse : {{adresse}}_  
ğŸ—“ï¸ _{{date formatÃ©e}}_  
ğŸ“ {{courte description}}

**RÃ¨gles Ã  suivre :**
- Un retour Ã  la ligne aprÃ¨s chaque ligne, puis une ligne vide entre chaque Ã©vÃ©nement.
- Le title est en gras `**`, les lieux et adresses en italique `_`.
- Formate les dates comme ceci :  
  â€¢ Pour une seule date : â€œle 4 mai 2025â€  
  â€¢ Pour une plage dans le mÃªme mois : â€œdu 4 au 12 mai 2025â€  
  â€¢ Pour deux mois diffÃ©rents : â€œdu 28 avril au 2 mai 2025â€
- Nâ€™ajoute aucun lien externe.
- Ne mentionne que les Ã©vÃ©nements prÃ©sents dans le CONTEXTE.
- Si possible rÃ©pond avec au moins 2 Ã©vÃ©nements pertinents.
- Si la question est floue, demande des prÃ©cisions Ã  l'utilisateur.
- Si la question est hors sujet, indique que tu ne rÃ©ponds que sur les Ã©vÃ©nements Ã  Paris.
- Termine chaque rÃ©ponse par **â€œAs-tu dâ€™autres questions ?â€**

---

CONTEXTE :  
{context_str}

---

QUESTION :  
{question}

---

RÃ‰PONSE DE Lâ€™ASSISTANT :
"""

# --- Historique conversationnel ---
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "Salut ğŸ‘‹ Je peux te recommander des Ã©vÃ©nements Ã  Paris. Pose-moi ta question !"}
    ]

st.title("ğŸ™ï¸ Assistant Ã‰vÃ©nements Ã  Paris")

# --- Affichage historique des messages ---
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# --- Formatage dynamique des documents (pour affichage assistant) ---
def format_doc(doc, score):
    title = doc.metadata.get("title", "Titre inconnu")
    lieu = doc.metadata.get("location_name", "Lieu inconnu")
    adresse = doc.metadata.get("location_address", "Adresse inconnue")
    debut = doc.metadata.get("firstdate_begin", "?")
    fin = doc.metadata.get("lastdate_end", "?")
    description = doc.page_content.strip()

    return (
        f"ğŸ“Œ **{title}**  \n"
        f"ğŸ“ _Lieu : {lieu}_  \n"
        f"ğŸ  _Adresse : {adresse}_  \n"
        f"ğŸ—“ï¸ _du {debut} au {fin}_  \n"
        f"ğŸ“ {description}"
    )

# --- Enrichissement des contextes pour RAGAS ---
def enrich_with_metadata(doc):
    title = doc.metadata.get("title", "")
    lieu = doc.metadata.get("location_name", "")
    adresse = doc.metadata.get("location_address", "")
    debut = doc.metadata.get("firstdate_begin", "")
    fin = doc.metadata.get("lastdate_end", "")
    description = doc.page_content.strip()
    return f"{title} - {lieu} - {adresse} - du {debut} au {fin} - {description}"

# --- EntrÃ©e utilisateur ---
if user_input := st.chat_input("Quel type d'Ã©vÃ©nement t'intÃ©resse ?"):

    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.write(user_input)

    try:
        results = vectorstore.similarity_search_with_score(user_input, k=4)

        # Texte enrichi pour affichage assistant
        context_str = "\n\n---\n\n".join([format_doc(doc, score) for doc, score in results])

        # Contextes enrichis pour logs et Ã©valuation RAGAS
        raw_contexts = [enrich_with_metadata(doc) for doc, score in results]

        print("âœ… placeholder_contexts pour RAGAS :")
        print(json.dumps(raw_contexts, indent=2, ensure_ascii=False))

    except Exception:
        st.error("âŒ Erreur pendant la recherche vectorielle.")
        results = []
        context_str = "Aucune information pertinente trouvÃ©e."
        raw_contexts = []

    # Prompt final
    final_prompt = SYSTEM_PROMPT.format(context_str=context_str, question=user_input)

    # Appel Ã  lâ€™API Mistral
    with st.chat_message("assistant"):
        placeholder = st.empty()
        placeholder.markdown("âŒ›")

        try:
            response = client.chat(
                model=model,
                messages=[ChatMessage(role="user", content=final_prompt)],
                temperature=0.2,
                top_p=0.9
            )
            assistant_reply = response.choices[0].message.content
        except Exception:
            assistant_reply = "DÃ©solÃ©, je nâ€™ai pas pu traiter ta demande. RÃ©essaie plus tard."

        placeholder.markdown(assistant_reply, unsafe_allow_html=False)

    st.session_state.messages.append({"role": "assistant", "content": assistant_reply})
